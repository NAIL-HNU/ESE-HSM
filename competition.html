<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8" />
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>ESE-HSM</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/prism/prism.css" rel="stylesheet" type="text/css">
  <link href="assets/vendor/prism/prism-treeview.css" rel="stylesheet" type="text/css">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</head>

<body class="homepage">
  <!-- <div id="page-wrapper"> -->
    <!-- ======= Header ======= -->
    <header id="header" class="fixed-top ">
      <div class="container-fluid">
        <div class="row justify-content-center">
          <div class="col-xl-10 d-flex align-items-center justify-content-between">
            <!-- <h1 class="logo"><a href="index.html"><img src="assets/img/university.png" alt="" class="img-fluid">&nbsp;<img src="assets/img/nail.png" alt="" class="img-fluid">&nbsp;&nbsp;IROS 2025 EVO Challenge</a></h1> -->
            <h1 class="logo"><a href="index.html"> IROS 2025 EVO Challenge</a></h1>
            <nav class="nav-menu d-none d-lg-block">
              <ul>
                <li ><a href="index.html">Home</a></li>
                <li class="drop-down"><a>About</a>
                  <ul>
                    <li><a href="sensor_suite.html">Sensor Suite</a></li>
                    <li ><a href="data_format.html">Data Format</a></li>
                  </ul>
                </li>
                <li ><a href="download.html">Download</a></li>
                <li class="active"><a href="competition.html">SLAM Challenge</a></li>
              </ul>
            </nav><!-- .nav-menu -->
            <a href="submit.html" class="get-started-btn scrollto">Submit</a>
          </div>
        </div>
      </div>
    </header><!-- End Header -->
  
<div class="wrapper">
<div class="container">
<article id="content">
  <div class="section-title"><h2>SLAM Challenge</h2></div>
  <p>The IROS 2025 Event-based Vision Challenge focuses on leveraging the high temporal resolution of event cameras to enhance SLAM/VO (VIO) systems. We hope participants will develop innovative solutions that apply the unique capabilities of event cameras to address challenges faced by four common types of platforms in dynamic environments.</p>

  <div class="section-title"><h2>Tracks</h2></div>
  <ul>
    <li><b>Event-Only:</b> SLAM/VO (VIO) systems using event cameras as the visual input. </li>
    <li><b>Event + Grayscale:</b> SLAM/VO (VIO) systems using event cameras combined with grayscale images as the visual input. </li>
  </ul>

  <div class="section-title"><h2>Data</h2></div>
  <ul>
    <li><p><a href=""><b>seq1 (20G)</b></a>&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;<a href=""><b>Calibration (1G)</b></a>&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;<a href=""><b>Reference timestamps (1G)</b></a><br></li>
      <li><p><a href=""><b>seq2 (20G)</b></a>&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;<a href=""><b>Calibration (1G)</b></a>&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;<a href=""><b>Reference timestamps (1G)</b></a><br></li>
  </ul>

  <!-- Evaluation Metrics -->

  <div class="section-title"><h2>Evaluation</h2></div>

  <p>
    In this challenge, we quantify the results using a combination of <b>Absolute Trajectory Error (ATE)</b> and <b>Area Under Curve (AUC)</b> based on the weighted success-rate curve. ATE is used to assess the global consistency of the estimated trajectory, while AUC is computed from a novel linear velocity evaluation metric that accounts for velocity-dependent performance across different operating speeds. By combining ATE and AUC, we can not only measure long-term trajectory accuracy but also emphasize the system's ability to handle high-speed maneuvers, providing a more comprehensive evaluation of SLAM/VO (VIO) systems in high-speed scenarios.
  </p>

  <ul>
      <li><b>ATE:</b> The Absolute Trajectory Error (ATE) quantifies the global consistency of the estimated trajectory by comparing it to the ground truth. It is particularly useful for assessing long-term drift and overall accuracy throughout the trajectory. ATE is defined as:</li>
  </ul>

  <ul>
      $$ 
      \text{ATE} = \frac{1}{N} \sum_{i=1}^{N} \left\| \mathbf{p}_i - \mathbf{p}_{i,\text{gt}} \right\|
      $$
  </ul>

  <ul>
      <li><b>AUC:</b> The Area Under Curve (AUC) is a unified metric introduced in this challenge to evaluate the performance of velocity estimation systems. It is computed from the weighted success-rate curve \( S_{\xi} \), which quantifies the proportion of velocity estimates where the Relative Velocity Error (RVE) is below a threshold \( \xi \).</li>
  </ul>

  <ul>
      Velocity estimation is evaluated using the Relative Velocity Error (RVE):
  </ul>

  <ul>
      $$ 
      \text{RVE} = \frac{\Vert \mathbf{v}_{\text{gt}} - \mathbf{v}_{\text{est}} \Vert_2}{\Vert \mathbf{v}_{\text{gt}} \Vert_2} \times 100\%
      $$
  </ul>

  <ul>
      We define the weighted success-rate curve \( S_{\xi} \) as the proportion of velocity estimates with RVE below a threshold \( \xi \):
  </ul>

  <ul>
      $$ 
      S_{\xi} = \frac{\sum_{i}^{N} \left\| \mathbf{v}_{\text{gt},i} \right\| \cdot \delta(e_{\text{RV},i} < \xi)}{\sum_i^{N} \left\| \mathbf{v}_{\text{gt},i} \right\|}
      $$
  </ul>

  <ul>
      The Area Under Curve is computed from the weighted success-rate curve \( S_{\xi} \). This ensures that successful estimates during high-speed motion contribute more significantly to the metric, resulting in higher AUC values.
  </ul>



  <script type="text/javascript">
    MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
  </script>


  <div class="section-title"><h2>Submit</h2></div>
  <p><strong>The trajectory from the left event camera is expected.</strong>  For each of the 10 trajectories in 
    the testing data, compute the camera poses, and save them in the text file with the name seq00X.txt. 
    Put all 10 files into a zip file with the following structure: </p>
    <div class="row">

      <div class="col-md-12"> 
      <pre><code class="language-treeview">
      EVO_Results.zip/
      |-- seq001.txt
      |-- seq002.txt
      |-- ...
      |-- seq00X.txt
      </code></pre>
        <p>Note that our automatic evaluation tool expects the estimated trajectory to be in this format.</p>

        <ul>
          <li>
          <p>Each line follows the format: <code class="lang-python">timestamp tx ty tz qx qy qz qw vx vy vz wx wy wz</code>.</p>
          </li>
          <li>
          <p>The value <code class="lang-python">timestamp</code> specifies the time at which a pose estimate should be provided, based on the timestamps listed in the <strong>Reference timestamps</strong> file.</p>
          </li>
          <li>
          <p>The values <code class="lang-python">tx ty tz</code> represent the position of the event camera's optical center relative to the world origin, expressed in the world coordinate frame.</p>
          </li>
          <li>
          <p>The values <code class="lang-python">qx qy qz qw</code> represent the orientation of the event camera's optical center with respect to the world frame.</p>
          </li>
          <li>
          <p>The values <code class="lang-python">vx vy vz</code> represent the velocity of the event camera's optical center relative to the world origin, expressed in the world coordinate frame.</p>
          </li>
          <li>
          <p>The values <code class="lang-python">wx wy wz</code> represent the angular velocity of the event camera's optical center relative to the world origin, expressed in the world coordinate frame.</p>
          </li>
          </div>
    </div>
    <div class="section-title"><h2>Timeline</h2></div>
      <li>
      <strong>Start Time: </strong>July 1, 2025 
      </li>
      <li>
        <strong>End Time: </strong>October 1, 2025 
      </li>

    <div class="section-title"><h2>Terms</h2></div>
      <li>
      <strong>General Terms: </strong>...
      </li>

      </article>

<!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> -->

<!-- <div class="section-title"><h2>Leaderboard</h2></div>
<form method="post" action="eval_semantic_seg_detail.php"><table class="table table-striped table-borderless">
  <tr class="heading">
    <td class="results"></td>
     <td class="results">Method</td>
     <td class="results">Setting</td>
     <td class="results">Code</td>
     <td class="results"><span style="color:#009961"><u>ATE</u></span></td>
     <td class="results">RPE</td>
     <td class="results">Runtime</td>
     <td class="results">Environment</td>
   </tr>
   <tr>
    <td class="results">1</td>
     <td class="results"><a href="">esvo2</a></td>
     <td class="results"></td>
     <td class="results"><a href="https://github.com/NAIL-HNU/ESVO2" target="blank">code</a></td>
     <td class="results"><b>...</b></td>
     <td class="results"><b>...</b></td>
     <td class="results">...</td>
     <td class="results">1 core @ 2.5 Ghz (C/C++)</td>
   </tr>
   <tr>
    <td class="results_sub" colspan="9">J. Niu, S. Zhong, X. Lu, S. Shen, G. Gallego and Y. Zhou: <a href="https://ieeexplore.ieee.org/document/10912788"> ESVO2: Direct Visual-Inertial Odometry With Stereo Event Cameras</a>. TRO 2025.<br/></td>
   </tr>
   
 </table></form> -->

<!-- <center><a target="_blank" href="table_semantic_seg.php?&benchmark=semantic2d&mode=1"> Table as LaTeX</a> | <a target="_blank" href="table_semantic_seg.php?&benchmark=semantic2d&mode=2"> Only published Methods</a></center><br><br> -->


</article>
</div></div>
<br class="clear">
    <!-- ======= Footer ======= -->
    <footer id="footer">
      <div class="container">
        <div class="copyright">
          &copy; 2025 | <a href="">Terms of Service</a> | <a href="">Imprint</a> | <a href="https://bootstrapmade.com/">BootstrapMade</a>
        </div>
      </div>
    </footer><!-- End Footer -->
</div>

<!-- Vendor JS Files -->
<script src="assets/vendor/jquery/jquery.min.js"></script>
<script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
<script src="assets/vendor/php-email-form/validate.js"></script>
<script src="assets/vendor/waypoints/jquery.waypoints.min.js"></script>
<script src="assets/vendor/counterup/counterup.min.js"></script>
<script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
<script src="assets/vendor/venobox/venobox.min.js"></script>
<script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>
<script src="assets/vendor/aos/aos.js"></script>
<script src="assets/vendor/prism/prism.js"></script>
<script src="assets/vendor/prism/prism-treeview.js"></script>

<!-- Template Main JS File -->
<script src="assets/js/main.js"></script>
</body>
</html>
